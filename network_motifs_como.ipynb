{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0f77fd",
   "metadata": {},
   "source": [
    "# Network motifs\n",
    "In this notebook, we will be exploring how to work with network motifs. You will first need the following two modules. Networx is one of the main network science libraries for python. It has many functions built in for network analysis https://networkx.org/. We will also need the packages below. You may already have them installed, if so, you can skip the first cell, and just load them in the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tabulate\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install networkx\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import random as rd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c896dc",
   "metadata": {},
   "source": [
    "We will investigate motifs in the network of network science collaborations, so first let's load the data that you are interested in. Here, I included two sources of data: one of the european road network, and one collaboration network of network scientist. Choose whichever you like, and comment the other one out. \n",
    "\n",
    "###  <font color='red'>When using Jupyter notebook on donwloaded GitHub folder, run the cell below</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d27261",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_adjlist(\"netsci_data.txt\")     #read adjacency list into a graph object\n",
    "G = nx.read_adjlist(\"euroroad.txt\")     #read adjacency list into a graph object\n",
    "\n",
    "print('Number of nodes', len(G.nodes))\n",
    "print('Number of edges', len(G.edges))\n",
    "avgdeg = sum(dict(G.degree).values()) / len(G.nodes)\n",
    "print('Average degree', avgdeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04147e52",
   "metadata": {},
   "source": [
    "### <font color='red'>When using Google collab run the two cells below instead:</font>\n",
    "\n",
    "The rest of the notebook is the same regardless of which method you used. Again, to change to another data set, comment the one that you do not use out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/clarastegehuis/Lake_como_school/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_adjlist('/content/Lake_como_school/euroroad.txt')     #read adjacency list into a graph object\n",
    "G = nx.read_adjlist('/content/Lake_como_school/netsci_data.txt')     #read adjacency list into a graph object\n",
    "\n",
    "print('Number of nodes', len(G.nodes))\n",
    "print('Number of edges', len(G.edges))\n",
    "avgdeg = sum(dict(G.degree).values()) / len(G.nodes)\n",
    "print('Average degree', avgdeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e987c29",
   "metadata": {},
   "source": [
    "## Exercise 1 \n",
    "Count the number of triangles in the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeeb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_count = sum(nx.triangles(G).values()) / 3 #In networkx, every triangle is counted 3 times, due to reordering of the vertices\n",
    "print(triad_count, \" triangles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce5b5a",
   "metadata": {},
   "source": [
    "Now let's say that we take an Erdos Renyi model as a null model to test for whether a statistically significant number of triangles is present. First figure out what the correct values of $n$ and $p$ are to compare the ER-model with your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n =                # fill in the correct value of n to compare to the data\n",
    "p =      # fill in the correct value of p to compare to the data\n",
    "print('p = ', p, ' n = ', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fdc88",
   "metadata": {},
   "source": [
    "With these values for $n$ and $p$, we can generate let's say 100 ER models that should serve as null models for the data sets, and count triangles in those null models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triad_counts = []  # vector with triangle counts in the ER model\n",
    "for i in range(100):\n",
    "    G_test = nx.erdos_renyi_graph(n,p)\n",
    "    test_triad_counts.append(sum(nx.triangles(G_test).values()) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6cd4b",
   "metadata": {},
   "source": [
    "Now plot a histogram of the generated triangle counts from the ER model together with the triangle count in the network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triads(countvec,datacount):    #This function plots a histogram of countvec, with a horizontal line at datacount\n",
    "    fig, ax = plt.subplots(figsize =(10, 7))\n",
    "    ax.hist(countvec, alpha = 0.65)\n",
    "    plt.style.use(\"bmh\")\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(left = False, bottom = False)\n",
    "    for ax, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "    plt.xlabel(\"triangle counts\",size = 17)\n",
    "    plt.ylabel(\"frequency\",size = 17)\n",
    "    plt.axvline(datacount, color = 'k', linestyle='dashed', linewidth=2)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triads(test_triad_counts,triad_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d126077",
   "metadata": {},
   "source": [
    "Now compute the Z-score of the triangle counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc008253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zscore(countvec,datacount):       #compute the Z score of datacount, when the null model produces as samples countvec\n",
    "    meancount = np.average(countvec)\n",
    "    std_count = np.std(countvec)     # standard deviation of triangle counts in null model\n",
    "    return (datacount-meancount)/std_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Zscore is ',Zscore(test_triad_counts,triad_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91e249",
   "metadata": {},
   "source": [
    "### Configuration model\n",
    "Now let's try the same thing in the configuration model. The input for the configuration model is a degree sequence, and it creates a random graph on those degrees. So first generate the correct input for the configuration model to be able to compare it to the data, and then compare triangle counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence =  # Pick the correct degree sequence to compare to the network data\n",
    "\n",
    "test_triad_config = []\n",
    "for i in range(100):\n",
    "    G_config = nx.configuration_model(degree_sequence)\n",
    "    G_config= nx.Graph(G_config)\n",
    "    test_triad_config.append(sum(nx.triangles(G_config).values()) / 3)\n",
    "plot_triads(test_triad_config,triad_count)\n",
    "print('Zscore is ',Zscore(test_triad_config,triad_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec7aeb",
   "metadata": {},
   "source": [
    "### Geometric random graph \n",
    "Now let's try yet another null model, the geometric random graph. Here, the input parameters are the radius $r$ and the number of vertices $n$. This model assumes that all $n$ vertices are uniformly placed in a $[0,1]^2$ box, and that every vertex connects with vertices within radius $r$. First, find the values of $r$ and $n$ for which you would be able to compare them to your data set, and then compare triangle counts. You may need that np.pi is the number $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius =  np.sqrt(avgdeg/(n*np.pi)) # compute the radius which makes the Geometrc random graph a good null model for the data\n",
    "\n",
    "G_geom = nx.random_geometric_graph(n, radius)\n",
    "\n",
    "test_triad_geom = []\n",
    "for i in range(100):\n",
    "    G_geom = nx.random_geometric_graph(n, radius)\n",
    "    test_triad_geom.append(sum(nx.triangles(G_geom).values()) / 3)\n",
    "plot_triads(test_triad_geom,triad_count)\n",
    "print('Zscore is ', Zscore(test_triad_geom,triad_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493afd91",
   "metadata": {},
   "source": [
    "## Questions\n",
    "What are the differences between the different null models?\n",
    "\n",
    "Are triangles always significant according to the Z-score?\n",
    "\n",
    "Are there differences when selecting different data sets?\n",
    "\n",
    "What is a good null model for these data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd3b49",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "##  Other motifs\n",
    "We now investigate some other motif types. For simplicity, we will stick with cliques. First, lets generate a list of all cliques in the network, and a function that then counts all cliques of size $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bbbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clique_list = nx.enumerate_all_cliques(G)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d247c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliquenumber(cliques,k):                #A function that takes a list with all cliques in the graph, and then reports the number of k-cliques\n",
    "    k_clique_num = 0\n",
    "    for i in cliques:\n",
    "        if len(i)==k:\n",
    "            k_clique_num += 1\n",
    "    return k_clique_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b013b4b",
   "metadata": {},
   "source": [
    "Pick a value of $k$ that you are interested in (probably very large cliques do not appear so often, so you may want to choose it not so much bigger than 3). Then perform the clique count in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "clique_count_G = cliquenumber(clique_list,k)\n",
    "print(clique_count_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1394b",
   "metadata": {},
   "source": [
    "You can now try the different null models for larger clique sizes and compare. The code now has the ER graph as a null mode, but you can try the other two null models as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kclique_counts = []\n",
    "for i in range(100):\n",
    "    G_test = nx.erdos_renyi_graph(n,p)\n",
    "    G_test_cliques = nx.enumerate_all_cliques(G_test) \n",
    "    test_kclique_counts.append(cliquenumber(G_test_cliques,k))\n",
    "plot_triads(test_kclique_counts,clique_count_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c59526d",
   "metadata": {},
   "source": [
    "### Questions\n",
    "Do other $k$-cliques appear significantly often compared to the null models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685b873",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "## Sampling\n",
    "Sometimes it is not possible to count the exact number of subgraphs in a large networks due to large computation times. One of the solutions to this problem is to use sampling instead. Many methods to sample subgraphs exist, but here we focus on the simplest one of them, creating a subsample of the network where every node is included with probability $q$. Then, it computes subgraphs (in this case cliques) in the reduced graph. Figure out how to obtain an estimate for the number of cliques in the larger graph from this sampled clique count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021150ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_cliques(Graph,sample_prob,size): # This function takes in a graph Graph, and returns an estimated clique count for cliques of size 'size'\n",
    "    nsampled = int((1-sample_prob)*len(Graph.nodes()))\n",
    "    sample = rd.sample(list(Graph.nodes), nsampled)    \n",
    "    H=Graph.copy()\n",
    "    H.remove_nodes_from(sample)            #remove every vertex in Graph independently with probability 1-p\n",
    "\n",
    "    clique_list_sampled = nx.enumerate_all_cliques(H)  \n",
    "    sampled_clique_count = cliquenumber(clique_list_sampled,size)        # the clique count in the subsampled graph\n",
    "\n",
    "    estimated_clique_count =            # figure out how to compute the estimated clique count from sampled_clique_count\n",
    "    return estimated_clique_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fe1a4",
   "metadata": {},
   "source": [
    "The cell below creates 100 subgraph count estimates with sampling probability $q$, and plots them together with the data count (dashed line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.7\n",
    "sampledvec = []\n",
    "for i in range(100):\n",
    "    sampledvec.append(sampled_cliques(G,q,k))\n",
    "plot_triads(sampledvec,clique_count_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a02b4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "How close is the sampled subgraph count to the actual one?\n",
    "\n",
    "How small can $q$ be to still obtain accurate estimates?\n",
    "\n",
    "How does this depend on the clique size $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd4a46",
   "metadata": {},
   "source": [
    "# Part 4: Neighborhood sampling\n",
    "Below, we would like to create an unbiased neighborhood sampling algorithm to approximate the density of triangles. First, we define a function that computes the triangle density of a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triad_density(Graph):\n",
    "    sumpairs = 0\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    for d in degrees:\n",
    "        sumpairs += d*(d-1)/2\n",
    "    sumpairs -= 2* triad_count\n",
    "    return triad_count/sumpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triad_density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec5c36",
   "metadata": {},
   "source": [
    "Now, we create a neighborhood sampling algorithm to approximate the triangle density. Add the probabilities that the algorithm samples the paths and subgraphs below to complete it, and compare it to the empirical triad density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed16b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_edge_count = len(G.edges())\n",
    "S_triad=0                                                   #sum of weights for triangles\n",
    "S_tot=0                                                     #sum of weights for all 3-nodes subgraphs\n",
    "N_samples = 500                                             # The number of random samples\n",
    "for k in range(N_samples):                                        \n",
    "    random_sampled_edge = rd.sample(list(G.edges),1)        #sample random edge (u,v)\n",
    "    u = random_sampled_edge[0][0]\n",
    "    v = random_sampled_edge[0][1]\n",
    "    sample_list = []\n",
    "    for i in G[u]:\n",
    "        if i!=v:\n",
    "            sample_list.append(i)                           #add all neighbors of u to the list\n",
    "    for j in G[v]:\n",
    "        if j!=u:\n",
    "            sample_list.append(j)                           #add all neighbors of v to the list\n",
    "    if sample_list == []:\n",
    "        continue\n",
    "    w = rd.sample(sample_list,1)[0]                         #sample random vertex w  from the list\n",
    "    \n",
    "    if G.has_edge(u,w) and G.has_edge(v,w):                 # if u,v,w is a triangle\n",
    "        P=   #What is the probability that triangle (u,v,w) is sampled? You may use that the number of neighbors of a node u is len(G[u])\n",
    "        S_triad+=1/P\n",
    "    else:\n",
    "        if G.has_edge(u,w):\n",
    "            P=         #What is the probability that path (w,u,v) is sampled?\n",
    "        if G.has_edge(v,w):\n",
    "            P=         #What is the probability that path (u,v,w) is sampled?\n",
    "            \n",
    "    S_tot+=1/P\n",
    "print(S_triad/S_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559bc99",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "Instead of sampling or exact computation of the subgraph counts in your null model, it is sometimes also possible to obtain analytical estimates for them. This can get quite involved depending on the exact null models you use, but for the Erdos Renyi model this is still doable. You may use that\n",
    "$$\\text{Var}(N(\\triangle)) = \\sum_{i,j,k,s,t,u}P(i,j,k \\text{ and }{s,t,u}\\text{ triangles})-p^6 $$\n",
    "Now compare the mean and variance of the triangle counts you found experimentally with the mean and variance you computed analytically. Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_triads_mean =        # Compute the mean number of triangles\n",
    "theoretical_var =         # Compute the variance of the number of triangles\n",
    "\n",
    "experimental_mean = np.mean(test_triad_counts)              # Compute the mean number of triangles in the sampled ER graphs\n",
    "experimental_var = np.var(test_triad_counts)\n",
    "\n",
    "table = [[' ', 'Mean', 'Variance'], ['Experimental', experimental_mean,experimental_var ],['Theoretical', theoretical_triads_mean,theoretical_var ]]\n",
    "\n",
    "print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcf1d7",
   "metadata": {},
   "source": [
    "Compare the theoretical mean number of larger $k$ cliques as well to its sampled value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_cliques_mean =            # Compute the mean number of k-cliques\n",
    "experimental_mean = np.mean(test_kclique_counts) \n",
    "\n",
    "print('Theoretical mean ',theoretical_cliques_mean, 'Experimental mean ', experimental_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
